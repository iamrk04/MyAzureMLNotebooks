{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM Perf Benchmark\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the ml_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "\n",
    "ws_ml_client = MLClient.from_config(\n",
    "    DefaultAzureCredential()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pipeline job and submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.ai.ml import load_job\n",
    "\n",
    "\n",
    "job_paths = [\n",
    "    # path to yaml pipeline job\n",
    "]\n",
    "\n",
    "job_list = []\n",
    "for job_path in job_paths:\n",
    "    pipeline_job = load_job(job_path)\n",
    "    job = ws_ml_client.create_or_update(pipeline_job)\n",
    "    job_list.append(job)\n",
    "    print(job.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect results from completed job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from scripts.aml_run_utils import _download_outputs\n",
    "\n",
    "# modify the following variables\n",
    "models = \"34b\"\n",
    "exp_name = \"\"\n",
    "endpoint_sku = \"Standard_ND40rs_v2\"\n",
    "pipeline_sku = \"serverless\"\n",
    "model_params = {\n",
    "    \"top_p\": 0.5,\n",
    "    \"temperature\": 0.0001,\n",
    "    \"do_sample\": True,\n",
    "    \"return_full_text\": False,\n",
    "    \"max_new_tokens\": 50\n",
    "}\n",
    "\n",
    "endpoint_nodes = 1\n",
    "endpoint_concurrency_per_instance = 1\n",
    "n_samples = 100\n",
    "temp_dir = \"out/temp\"\n",
    "result_path = f\"out/result/{models}.csv\"\n",
    "df = pd.DataFrame()\n",
    "\n",
    "os.makedirs(temp_dir, exist_ok=True)\n",
    "os.makedirs(os.path.dirname(result_path), exist_ok=True)\n",
    "\n",
    "for job in job_list:\n",
    "    download_path = os.path.join(temp_dir, job.name)\n",
    "    os.makedirs(download_path, exist_ok=True)\n",
    "    job_name = job.name\n",
    "    output_name = job.outputs.perf_data.port_name\n",
    "    output_dir = f\"{download_path}/named-outputs/{output_name}\"\n",
    "\n",
    "    _download_outputs(ws_ml_client, job_name, download_path, output_name, all=True)\n",
    "\n",
    "    output_path = [\n",
    "        os.path.join(output_dir, file)\n",
    "        for file in os.listdir(output_dir) if file.endswith(\".jsonl\")\n",
    "    ][0]\n",
    "\n",
    "    temp_df = pd.read_json(output_path, lines=True)\n",
    "    latency_avg = temp_df[\"latency\"].mean()\n",
    "    latency_std = temp_df[\"latency\"].std()\n",
    "\n",
    "    metrics_json = {}\n",
    "    metrics_json[\"model\"] = job.display_name.split(\"__\")[0]\n",
    "    metrics_json[\"latency_ms_avg\"] = latency_avg\n",
    "    metrics_json[\"latency_ms_std\"] = latency_std\n",
    "    metrics_json[\"n_samples\"] = n_samples\n",
    "    metrics_json[\"endpoint-sku\"] = endpoint_sku\n",
    "    metrics_json[\"endpoint_nodes\"] = endpoint_nodes\n",
    "    metrics_json[\"endpoint_concurrency_per_instance\"] = endpoint_concurrency_per_instance\n",
    "    metrics_json[\"model_params\"] = json.dumps(model_params)\n",
    "    metrics_json[\"pipeline_sku\"] = pipeline_sku\n",
    "    metrics_json[\"run_id\"] = job_name\n",
    "    metrics_json[\"studio_url\"] = job.studio_url\n",
    "    \n",
    "    df = df.append(metrics_json, ignore_index=True)\n",
    "    shutil.rmtree(download_path)\n",
    "\n",
    "df.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results from mlfow logged metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "from scripts.aml_run_utils import get_mlflow_logged_metrics\n",
    "\n",
    "\n",
    "# modify the following variables\n",
    "exp_name = \"llm_perf\"\n",
    "model_family = \"orca\"\n",
    "model_params = {\n",
    "    \"top_p\": 0.5,\n",
    "    \"temperature\": 0.001,\n",
    "    \"do_sample\": True,\n",
    "    \"return_full_text\": False,\n",
    "    \"max_new_tokens\": 50\n",
    "}\n",
    "endpoint_sku = \"Standard_ND96amsr_A100_v4\"\n",
    "job_names = [\n",
    "    # job names\n",
    "]\n",
    "\n",
    "result_path = f\"out/result/{model_family}.csv\"\n",
    "pipeline_sku = \"serverless\"\n",
    "endpoint_nodes = 1\n",
    "endpoint_concurrency_per_instance = 1\n",
    "\n",
    "os.makedirs(os.path.dirname(result_path), exist_ok=True)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "for job_name in job_names:\n",
    "    metrics_json = {}\n",
    "    job = ws_ml_client.jobs.get(job_name)\n",
    "    metrics_json[\"model\"] = job.display_name.split(\"__\")[0]\n",
    "    metrics_json.update(get_mlflow_logged_metrics(ws_ml_client, job.name, exp_name))\n",
    "    metrics_json[\"endpoint_sku\"] = endpoint_sku\n",
    "    metrics_json[\"endpoint_nodes\"] = endpoint_nodes\n",
    "    metrics_json[\"endpoint_concurrency_per_instance\"] = endpoint_concurrency_per_instance\n",
    "    metrics_json[\"model_params\"] = json.dumps(model_params)\n",
    "    metrics_json[\"pipeline_sku\"] = pipeline_sku\n",
    "    metrics_json[\"run_id\"] = job_name\n",
    "    metrics_json[\"studio_url\"] = job.studio_url\n",
    "    \n",
    "    df = df.append(metrics_json, ignore_index=True)\n",
    "\n",
    "df.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the results df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify the following variables\n",
    "result_path = f\"out/result/{model_family}_cleaned.csv\"\n",
    "\n",
    "cleaned_df = df.drop(columns=[\"num_valid_entries\", \"ratio_valid_entries\", \"run_id\", \"model_params\", \"avg_rps\", \"std_rps\"])\n",
    "cleaned_df = cleaned_df[[\"model\", \"avg_generated_tps\", \"std_generated_tps\", \"avg_latency_ms\", \"std_latency_ms\", \"latency_p50\", \"latency_p90\", \"latency_p95\", \"latency_p99\", \"endpoint_sku\", \"endpoint_nodes\", \"endpoint_concurrency_per_instance\", \"pipeline_sku\", \"studio_url\"]]\n",
    "cleaned_df = cleaned_df.round(2)\n",
    "cleaned_df = cleaned_df.sort_values(by=[\"model\"])\n",
    "cleaned_df.to_csv(result_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot \"Latency vs Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(result_path)\n",
    "# create new column \"family\" for llama, codellama, falcon, etc\n",
    "df[\"family\"] = df[\"model\"].apply(lambda x: x.split(\"-\")[0])\n",
    "df[\"avg_latency_sec\"] = df[\"avg_latency_ms\"] / 1000\n",
    "df = df.sort_values(by=[\"avg_latency_sec\"])\n",
    "\n",
    "# plot\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax = sns.barplot(\n",
    "    x=\"model\",\n",
    "    y=\"avg_latency_sec\",\n",
    "    data=df,\n",
    "    palette=\"Blues_d\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment=\"right\")\n",
    "ax.set_xlabel(\"Model\", fontsize=16)\n",
    "ax.set_ylabel(\"Avg Latency (sec)\", fontsize=16)\n",
    "ax.set_title(\"Avg Latency (sec) vs Model\", fontsize=20)\n",
    "\n",
    "# put values on top of the bars\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f\"{p.get_height():.2f}\",\n",
    "        (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        xytext=(0, 10),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "\n",
    "# use different color for different family in bar chart with legend\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    if df.iloc[i][\"family\"] == \"llama\":\n",
    "        bar.set_color(\"tab:green\")\n",
    "    elif df.iloc[i][\"family\"] == \"codellama\":\n",
    "        bar.set_color(\"tab:cyan\")\n",
    "    else:\n",
    "        bar.set_color(\"tab:orange\")\n",
    "\n",
    "# add legend for used color\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"tab:green\", label=\"Llama\"),\n",
    "    # Patch(facecolor=\"tab:cyan\", label=\"Codellama\"),\n",
    "    Patch(facecolor=\"tab:orange\", label=\"Orca\"),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot \"Generated TPS vs Models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Patch\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "df = pd.read_csv(result_path)\n",
    "df[\"family\"] = df[\"model\"].apply(lambda x: x.split(\"-\")[0])\n",
    "df = df.sort_values(by=[\"avg_generated_tps\"])\n",
    "\n",
    "# plot\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax = sns.barplot(\n",
    "    x=\"model\",\n",
    "    y=\"avg_generated_tps\",\n",
    "    data=df,\n",
    "    palette=\"Blues_d\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, horizontalalignment=\"right\")\n",
    "ax.set_xlabel(\"Model\", fontsize=16)\n",
    "ax.set_ylabel(\"avg_generated_tps\", fontsize=16)\n",
    "ax.set_title(\"Avg Generated TPS vs Model\", fontsize=20)\n",
    "\n",
    "# put number on top of the bar\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f\"{p.get_height():.2f}\",\n",
    "        (p.get_x() + p.get_width() / 2, p.get_height()),\n",
    "        ha=\"center\",\n",
    "        va=\"center\",\n",
    "        xytext=(0, 10),\n",
    "        textcoords=\"offset points\",\n",
    "    )\n",
    "\n",
    "# use different color for different family in bar chart\n",
    "for i, bar in enumerate(ax.patches):\n",
    "    if df.iloc[i][\"family\"] == \"llama\":\n",
    "        bar.set_color(\"tab:green\")\n",
    "    elif df.iloc[i][\"family\"] == \"codellama\":\n",
    "        bar.set_color(\"tab:cyan\")\n",
    "    else:\n",
    "        bar.set_color(\"tab:orange\")\n",
    "\n",
    "# add legend for used color\n",
    "legend_elements = [\n",
    "    Patch(facecolor=\"tab:green\", label=\"Llama\"),\n",
    "    # Patch(facecolor=\"tab:cyan\", label=\"Codellama\"),\n",
    "    Patch(facecolor=\"tab:orange\", label=\"Orca\"),\n",
    "]\n",
    "ax.legend(handles=legend_elements, loc=\"upper left\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpv2_prev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
